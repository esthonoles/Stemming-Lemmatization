{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "68854f44",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "study : studi\n",
      "studying : studi\n",
      "studies : studi\n",
      "studied : studi\n"
     ]
    }
   ],
   "source": [
    "# Tugas Sistem Penunjang Keputusan NIM (3)\n",
    "# Nama : Abd Wahid\n",
    "# NIM : 181011401863\n",
    "# Kelas : 07TPLM010\n",
    "\n",
    "\n",
    "# Stemming dengan Algoritma PorterStemmer\n",
    "\n",
    "from nltk.stem import PorterStemmer\n",
    "porter = PorterStemmer()\n",
    "\n",
    "tokens = ['study', 'studying', 'studies', 'studied']\n",
    "\n",
    "for token in tokens :\n",
    "    print(token + \" : \" + porter.stem(token))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "347281fc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "study : studi\n",
      "studying : studi\n",
      "studies : studi\n",
      "studied : studi\n"
     ]
    }
   ],
   "source": [
    "# Stemming dengan algoritma SnowballStemmer\n",
    "from nltk.stem import SnowballStemmer\n",
    "\n",
    "snowball = SnowballStemmer(language='english')\n",
    "\n",
    "for token in tokens:\n",
    "    print(token + \" : \" + snowball.stem(token))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "4b7731ca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the\n",
      "ransomw\n",
      "attack\n",
      "impact\n",
      "krono\n",
      "priv\n",
      "cloud\n",
      "solv\n"
     ]
    }
   ],
   "source": [
    "# Stemming Sentences\n",
    "from nltk.stem import LancasterStemmer\n",
    "\n",
    "lancaster = LancasterStemmer()\n",
    "\n",
    "s = \"The ransomware attack impacts Kronos Private Cloud solutions\"\n",
    "\n",
    "words = word_tokenize(s)\n",
    "\n",
    "for w in words:\n",
    "    print(lancaster.stem(w))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "41f2d642",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /home/waeet/nltk_data...\n",
      "[nltk_data]   Unzipping tokenizers/punkt.zip.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('punkt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e81ddaf7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "study : study\n",
      "studying : study\n",
      "studies : study\n",
      "studied : study\n"
     ]
    }
   ],
   "source": [
    "from nltk.stem import LancasterStemmer\n",
    "\n",
    "lancaster = LancasterStemmer()\n",
    "\n",
    "for token in tokens:\n",
    "    print(token + \" : \" + lancaster.stem(token))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "4be7eb67",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Lorem Ipsum is simply dummy text of the printing and typesetting industry. Lorem Ipsum has been the industry's standard dummy text ever since the 1500s, when an unknown printer took a galley of type and scrambled it to make a type specimen book. It has survived not only five centuries, but also the leap into electronic typesetting, remaining essentially unchanged. It was popularised in the 1960s with the release of Letraset sheets containing Lorem Ipsum passages, and more recently with desktop publishing software like Aldus PageMaker including versions of Lorem Ipsum.\\n\""
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Tes Stemming Document\n",
    "file=open(\"textstemp.txt\")\n",
    "file.read()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "2e229d76",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[\"Lorem Ipsum is simply dummy text of the printing and typesetting industry. Lorem Ipsum has been the industry's standard dummy text ever since the 1500s, when an unknown printer took a galley of type and scrambled it to make a type specimen book. It has survived not only five centuries, but also the leap into electronic typesetting, remaining essentially unchanged. It was popularised in the 1960s with the release of Letraset sheets containing Lorem Ipsum passages, and more recently with desktop publishing software like Aldus PageMaker including versions of Lorem Ipsum.\\n\"]"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "file=open(\"textstemp.txt\")\n",
    "my_lines_list=file.readlines()\n",
    "my_lines_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "a63c8a10",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Lorem Ipsum is simply dummy text of the printing and typesetting industry. Lorem Ipsum has been the industry's standard dummy text ever since the 1500s, when an unknown printer took a galley of type and scrambled it to make a type specimen book. It has survived not only five centuries, but also the leap into electronic typesetting, remaining essentially unchanged. It was popularised in the 1960s with the release of Letraset sheets containing Lorem Ipsum passages, and more recently with desktop publishing software like Aldus PageMaker including versions of Lorem Ipsum.\n",
      "\n",
      "-- Stemmed Sentences --\n",
      "lorem ipsum is simpli dummi text of the print and typeset industri . lorem ipsum ha been the industri 's standard dummi text ever sinc the 1500 , when an unknown printer took a galley of type and scrambl it to make a type specimen book . it ha surviv not onli five centuri , but also the leap into electron typeset , remain essenti unchang . it wa popularis in the 1960 with the releas of letraset sheet contain lorem ipsum passag , and more recent with desktop publish softwar like aldu pagemak includ version of lorem ipsum . \n"
     ]
    }
   ],
   "source": [
    "def StemSentece(sentence):\n",
    "    token_words=word_tokenize(sentence)\n",
    "    token_words\n",
    "    stem_sentence=[]\n",
    "\n",
    "    for word in token_words:\n",
    "        stem_sentence.append(porter.stem(word))\n",
    "        stem_sentence.append(\" \")\n",
    "    return \"\".join(stem_sentence)\n",
    "\n",
    "\n",
    "print(my_lines_list[0])\n",
    "print(\"-- Stemmed Sentences --\")\n",
    "x=StemSentece(my_lines_list[0])\n",
    "print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "a0689dde",
   "metadata": {},
   "outputs": [],
   "source": [
    "stem_file=open(\"textstemp.txt\",mode=\"a+\", encoding=\"utf-8\")\n",
    "\n",
    "for line in my_lines_list:\n",
    "    stem_sentence=StemSentece(line)\n",
    "    stem_file.write(stem_sentence)\n",
    "    \n",
    "    stem_file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7594a9c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41ce0ec3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "cfcc2e9b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to /home/waeet/nltk_data...\n",
      "[nltk_data]   Unzipping corpora/wordnet.zip.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('wordnet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "7fbc2c32",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "study : study\n",
      "studying : studying\n",
      "studies : study\n",
      "studied : studied\n"
     ]
    }
   ],
   "source": [
    "from nltk.stem import WordNetLemmatizer\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "\n",
    "for token in tokens:\n",
    "    print(token + \" : \" + lemmatizer.lemmatize(token))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "333f8016",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Word                Lemma               \n",
      "The                 The                 \n",
      "ransomware          ransomware          \n",
      "attack              attack              \n",
      "impacts             impact              \n",
      "Kronos              Kronos              \n",
      "Private             Private             \n",
      "Cloud               Cloud               \n",
      "solutions           solution            \n"
     ]
    }
   ],
   "source": [
    "from nltk.stem import WordNetLemmatizer\n",
    "\n",
    "s = \"The ransomware attack impacts Kronos Private Cloud solutions\"\n",
    "words = word_tokenize(s)\n",
    "print(\"{0:20}{1:20}\".format(\"Word\",\"Lemma\"))\n",
    "for w in words:\n",
    "    print(\"{0:20}{1:20}\".format(w,lemmatizer.lemmatize(w)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c7c21ec",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab03cd81",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
